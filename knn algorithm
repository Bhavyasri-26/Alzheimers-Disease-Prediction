import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

df_long = pd.read_csv("oasis_longitudinal.csv")
df_long.head()

df_long.drop(df_long.columns[[0,1,3,4,6]], axis = 1, inplace = True) 
df_long.head()
df_long['SES'].fillna((round(df_long['SES'].mean())), inplace=True)
df_long['MMSE'].fillna((round(df_long['MMSE'].mean())), inplace=True)
df_long['CDR'].fillna((round(df_long['CDR'].mean())), inplace=True)
df_long['eTIV'].fillna((round(df_long['eTIV'].mean())), inplace=True)
df_long['nWBV'].fillna((round(df_long['nWBV'].mean())), inplace=True)
df_long['ASF'].fillna((round(df_long['ASF'].mean())), inplace=True)
df_long['M/F'] = df_long['M/F'].replace('F', 1)
df_long['M/F'] = df_long['M/F'].replace('M', 0)
df_long['Group'] = df_long['Group'].replace('Demented', 1)
df_long['Group'] = df_long['Group'].replace('Nondemented', 0)
df_long['Group'] = df_long['Group'].replace('Converted', 2)

array=df_long.values
X = array[:,[1,2,3,4,5,6,7,8,9]]
Y = array[:,0]
X_train, X_test, y_train,y_test=train_test_split(X,Y,random_state=10,test_size=0.2)

# try K=1 through K=25 and record testing accuracy
k_range = range(1, 26)
# We can create Python dictionary using [] or dict()
scores = []
# We use a loop through the range 1 to 26
# We append the scores in the dictionary
for k in k_range:
 knn = KNeighborsClassifier(n_neighbors=k)
 knn.fit(X_train, y_train)
 y_pred = knn.predict(X_test)
 scores.append(accuracy_score(y_test, y_pred))
print(scores)

# import Matplotlib (scientific plotting library)
import matplotlib.pyplot as plt
# allow plots to appear within the notebook
%matplotlib inline
# plot the relationship between K and testing accuracy
# plt.plot(x_axis, y_axis)
plt.plot(k_range, scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

classifier=KNeighborsClassifier(n_neighbors=6,p=2,metric='euclidean')
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

import pickle
pickle.dump(classifier,open("oasis_longitudinal_trial.sav","wb"))

from flask import Flask, render_template, request, jsonify, redirect, url_for
from werkzeug.wrappers import Request, Response
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
classifier = pickle.load(open("oasis_longitudinal_trial.sav","rb"))
app = Flask(__name__)


@app.route('/')
def index():
    return render_template('one.html')


@app.route('/one_set', methods=['GET'])
def one_set():
    global age, EDUC
    name = request.args.get('name', '')
    age = request.args.get('age', '')
    EDUC = request.args.get('yoe', '')
    return render_template('two.html')


@app.route('/two_set', methods=['GET'])
def two_set():
    global SES, MMSE, CDR

    SES = request.args.get('ses', '')
    MMSE = request.args.get('mmse', '')
    CDR = request.args.get('cdr', '')
    return render_template('three.html')


@app.route('/third_set', methods=['GET'])
def third_set():
    gender = request.args.get('gender', '')
    eTIV = request.args.get('etiv', '')
    nWBV = request.args.get('nwbv', '')
    ASF = request.args.get('asf', '')
    tp = [EDUC, SES, MMSE, CDR, gender, age, eTIV, nWBV, ASF]
    tp = np.array(tp)
    tp = tp.reshape(1, -1)
    value = classifier.predict(tp)[0]
    print(value)
    if value == 0:
        return render_template('result2.html')
    else:
        if 19 < int(MMSE) <=24 :
            return render_template('early.html')
        elif 10 < int(MMSE) <= 19:
            return render_template('moderate.html')
        else:
            return render_template('advanced.html')


@app.route("/home")
def home():
    return render_template('one.html')


if __name__ == '__main__':
    from werkzeug.serving import run_simple
    run_simple('localhost',5000,app)
    #app.run(host='localhost',port=,debug=True,threaded=True)
    
 
